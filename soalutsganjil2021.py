# -*- coding: utf-8 -*-
"""SoalUTSGanjil2021.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HkfvNFgdb0vufBkQUXda_4_cRSbpokdB

## **Tugas Besar Pengganti Ujian Tengah Semester (UTS), Semester Ganjil 2020/2021**
### Deadline: 10 November 2020, Jam 12.00 (siang)
##### Dosen: FYS, ITQ, HBU

## 1. Regresi

<img src="BeratIkan.png" alt="GDP" width="600"/>
<div style="text-align: center">
<center>Gambar 1: Ilustrasi feature-feature untuk estimasi/prediksi berat ikan

Joko ingin melakukan prediksi/estimasi berat atau panjang ikan berdasarkan pengamatan ukuran ikan (panjang/lebar) seperti yang diilustrasikan pada Gambar 1. Joko telah mengumpulkan Dataset ikan yang dijual di pasar dengan spesies ikan yaitu *bream, white fish, perch, roach fish, pike* dan *smelt* dan anda dapat mengaksesnya pada berikut [**Data Ikan 1**](https://drive.google.com/file/d/1atDUbrpW2W9YmB43bk3quZ4_HR_gEi-D/view?usp=sharing). 

Karena Joko belum pernah mengambil matakuliah Machine Learning, Joko bingung menentukan model yang akan digunakan dan ingin meminta bantuan anda sebagai seorang konsultan *Machine Learning*. Anda diminta Joko menemukan model yang tepat untuk mengestimasi berat dan panjang ikan tersebut dengan kinerja yang baik. Setiap kelompok bekerja dengan dataset yang sama tetapi dengan aturan berikut:

1. Kelompok 1, prediksi berat ikan menggunakan parameter a (Length1) dengan Regresi (linier/polinomial)
2. Kelompok 2, prediksi berat ikan menggunakan parameter d (Width) dengan Regresi (linier/polinomial)
3. Kelompok 3, prediksi berat ikan menggunakan parameter e (Height) dengan Regresi (linier/polinomial) pada jenis ikan perch
4. Kelompok 4, prediksi berat ikan menggunakan parameter b (Length2) dengan Regresi (linier/polinomial)
5. Kelompok 5, prediksi panjang ikan(Length3) menggunakan parameter (Weight) dengan Regresi (linier/polinomial)
6. Kelompok 6, prediksi berat ikan menggunakan parameter a(Length1) dengan jenis ikan Perch menggunakan Regresi (linier/polinomial)
7. Kelompok 7, prediksi berat ikan menggunakan ciri b (Length2) dengan jenis ikan bream menggunakan Regresi (linier/polinomial)
8. Kelompok 8, prediksi berat ikan berdasarkan fitur (Height) dengan Regresi (linier/polinomial) pada jenis ikan Roach.

#### **Berikut adalah langkah-langkah solusi yang anda gunakan untuk membantu Joko menemukan model regresi terbaik**

* Copy dataset yang ada pada link di atas ke dalam direktori lokal masing-masing (untuk memudahkan tempatkan pada folder yang sama dengan file Tugas Besar anda).


**A. Load dataset dalam format CSV tersebut dan plot data target vektor sebagai sumbu y dan matriks *feature* x (berdimensi 1) sebagai sumbu x**

Catatan: yang diplot hanya yang diperlukan. Misalkan untuk kelompok 1, berat ikan (Weight) sebagai target vektor (sumbu y) dan panjang ikan (Length1) sebagai matriks *feature* (sumbu x).
"""

# kode untuk poin A di sini
# kode untuk poin A di sini
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns

fish = pd.read_csv('Fish.csv')
x = fish['Length2'].to_numpy()
y = fish['Weight'].to_numpy()


plt.scatter(x, y,color = 'orange')
plt.xlabel('feature, x, Lenghth2')
plt.ylabel('target, y, Weight')
plt.show()
print(fish)

"""**B. Atur data ke dalam matriks feature X dan target vektor y dimana data sesuai dengan kelompok masing-masing**

Catatan: Pengaturan ini dilakukan supaya bisa digunakan pada soal C (sesuai format data `Scikit Learn`)
"""

# kode poin B di sini
X = x[:,np.newaxis]
y = y[:,np.newaxis]
print(X,y)

"""**C. Memilih Model Class, dan Penentuan Hyperparameter (jika ada)**

Catatan: 
- Dengan melihat plotting data pada poin A, maka pastikan berapa orde polinomial yang ingin anda gunakan (belum tentu garis lurus). Lihat lecture note **Chapter 2**.
- Jika memungkinkan pilihlah orde polinomial dengan metode pemilihan model terbaik seperti pada lecture note **Chapter 3**, bagian **4. Memilih Model Terbaik**.
"""

# Memilih orde terbaik

from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.pipeline import make_pipeline


#Model regresi
def PolynomialRegression(degree=2, **kwargs):
     return make_pipeline(PolynomialFeatures(degree),LinearRegression(**kwargs))

#membuat validasi kurva


from sklearn.model_selection import validation_curve
degree = np.arange(0, 15)


#validasi kurva untuk semua derajat
train_score, val_score = validation_curve(PolynomialRegression(), X, y,'polynomialfeatures__degree', degree,cv=7) #7 fold cross validation
plt.plot(degree, np.median(train_score, 1), color='blue', label='training score')
plt.plot(degree, np.median(val_score, 1), color='red', label='validation score')
plt.legend(loc='best')
plt.ylim(0, 1)
plt.xlim(0, 10,1)
plt.xlabel('degree')
plt.ylabel('score');

"""**D. Melakukan *fitting* model terhadap data (training)**

Catatan: Setelah memilih model class, gunakan model tersebut untuk melakukan training dengan data dari poin B.
"""

# kode poin D di sini
#visualiasi orde dengan dataset

X_test = np.linspace(0,60)[:, None]
    
plt.scatter(X, y, color='black')
axis = plt.axis()
for degree in [2,3,5,8]:
    #fitting data into polynomial model
    y_test = PolynomialRegression(degree).fit(X, y).predict(X_test)
    plt.plot(X_test, y_test, label='degree={0}'.format(degree))
plt.legend(loc='best');

#setelah melakukan fitting kita lakukan validasi untuk menentukan orde terbaik

"""**E. Memprediksi data baru**

Catatan: Buat data baru (harga-harga feature) dengan range dari harga minimum ke harga maksimum feature yang anda gunakan pada data poin B (matriks feature X), misalkan dengan `linspace()` dari `Numpy`. Kemudian prediksi harga-harga target (y) berdasarkan harga feature tersebut. Selanjutnya anda ploting data training dengan data hasil prediksi pada langkah ini. (lihat **Chapter 3**)
"""

# kode poin E di sini
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline
from sklearn.linear_model import LinearRegression
degree=8
X_seq = np.linspace(X.min(),X.max(),100).reshape(-1,1) # min ke max
polyreg=make_pipeline(PolynomialFeatures(degree),LinearRegression())
polyreg.fit(X,y)
plt.figure(figsize=(10,5))
plt.plot(X,y,'b.',label='training data')
plt.plot(X_seq,polyreg.predict(X_seq),'r-',label='prediction')
plt.xlabel('feature, x')
plt.ylabel('target, y')
plt.legend(loc='upper left')
plt.show

"""**Kesimpulan**. Berikan kesimpulan model apa yang akan anda rekomendasikan kepada Joko setelah anda mengikuti langkah A-E (sesuai dengan kelompok masing-masing).

Orde 5 dan 8 model yang saya rekomendasikan kepada joko karena memiliki nilai validasi yang tinggi.

## 2. Klasifikasi dengan Regresi Logistik dan Stochastic Gradient Descent (SGD)

Berlanjut dengan cerita Joko. Selain ingin memprediksi berat atau panjang ikan, Joko juga tertarik untuk melakukan klasifikasi apakah ikan tertentu termasuk ikan Gurame atau Ikan Mujair. Kemudian dia memutuskan, klasifikasi adalah berdasarkan *feature* berat dan juga panjang. Hasil pengumpulan data Joko dapat dilihat pada link berikut ini: [**Data Ikan 2**](https://drive.google.com/file/d/1DBlEemGWKSaLb4X6W7PLDpccWCFF3VnD/view?usp=sharing). 

Pada data tersebut, kolom pertama menyatakan berat ikan (dalam gram), kolom kedua menyatakan panjang ikan (dalam cm) dan kolom ketiga menyatakan jenis ikan, dimana ikan Gurame dikodekan dengan angka 1, sedangkan ikan Mujair dikodekan dengan angka 0. Karena Joko sudah sedikit paham menyangkut *Machine Learning*, dia meminta anda untuk menggunakan Metode Regresi Logistik dan SGD dalam melakukan klasifikasi, untuk kemudian membandingkannya.

#### **2.1. Berikut adalah langkah-langkah solusi Regresi Logistik yang anda gunakan untuk membantu Joko melakukan klasifikasi jenis ikan Gurame atau Ikan Mujair**

* Copy dataset yang ada pada link di atas ke dalam direktori lokal masing-masing (untuk memudahkan tempatkan pada folder yang sama dengan file Tugas Besar anda).
* Setiap kelompok menggunakan dataset yang sama


**A. Load dataset dalam format CSV tersebut** 

* Anda bisa menggunakan package `Pandas` maupun `Numpy`.
"""

# Kode poin A di sini
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns



fish2 = pd.read_csv('IkanIndo01.csv') # saya sudah rubah csvnya dengan ditambah weight,length,jenis
print(fish2)

"""**B. Atur data ke dalam matriks feature X dan target vektor y, kemudian plot data dalam dua dimensi**

Catatan: sumbu x --> Feature 1 (berat ikan), sumbu y --> Feature 2 (panjang ikan), untuk *class* ikan Gurame (1) gunakan *square* warna biru (`'bs'`) dan untuk *class* ikan Mujair (0) gunakan *circle* warna hijau (`'ho'`). Sebagai contoh anda bisa lihat di **Chapter 2**.   
"""

Gurame = fish2.loc[(fish2['Jenis'] == 1)]
Mujair = fish2.loc[(fish2['Jenis'] == 0)]
WeightGurame = Gurame['Weight']
LengthGurame = Gurame['Length']
WeightMujair = Mujair['Weight']
LengthMujair = Mujair['Length']
plt.figure(figsize=(14,7))
plt.plot(WeightGurame, LengthGurame, "bs", linewidth=0, label="Ikan Gurame")
plt.plot(WeightMujair, LengthMujair, "go", linewidth=0, label="Ikan Mujair")
plt.xlabel("Weight", fontsize=18)
plt.ylabel("Length", fontsize=18)
plt.legend()
plt.show()

"""**C. Memilih Model Class, dan Penentuan Hyperparameter (jika ada)**

Catatan: 
- Gunakan model Regresi Logistik 
"""

# Kode poin C di sini
from sklearn.linear_model import LogisticRegression

"""**D. Melakukan *fitting* model terhadap data (training)**

Catatan: Setelah memilih model class, gunakan model tersebut untuk melakukan training dengan data dari poin B.
"""

jenisIkan = fish2.drop(["Jenis"], axis=1).astype(np.float64)
X_train = np.matrix(jenisIkan.values)
jenisIkan = fish2.drop(["Weight","Length"], axis=1).astype(np.int64)
y_train = np.matrix(jenisIkan.values)
log_reg = LogisticRegression()
log_reg.fit(X_train,y_train)

"""**E. Memprediksi data baru**

Jika terdapat dua ekor ikan, dimana ikan 1 dengan berat = 200 gram dan panjang = 30 cm, sedangkan ikan 2 berat = 600 gram dan panjang = 40 cm. Tentukan jenis kedua ikan tersebut apakah ikan Gurame atau Mujaer berdasarkan model anda.
"""

# kode poin E di sini
# prediksi
ikan=log_reg.predict([[200,30], [600,40]]) 
if ikan[0] == 1:
  print("ikan 1 adalah jenis ikan gurame")
else:
  print("ikan 1 adalah jenis ikan mujair")
if ikan[1] == 1:
  print("ikan 2 adalah jenis ikangurame")
else:
  print("ikan 2 adalah jenis ikan mujair")

"""**F. Plotting Batas Keputusan (*Decision Boundary*)**

Gambar data seperti pada poin B, tetapi tambahkan batas keputusan (berupa garis lurus) yang memisahkan antara data ikan Gurame dan ikan Mujair (lihat **Chapter 2**, bagian **2.3.Contoh Python untuk Regresi Logistik**)
"""

# kode poin F di sini
b = log_reg.intercept_[0]
w1, w2 = log_reg.coef_.T
c = -b/w2
m = -w1/w2

axisx = fish2.drop(["Length","Jenis"], axis=1).astype(np.int64)
xd = np.array(axisx.values)
yd = m*xd + c


Gurame = fish2.loc[(fish2['Jenis'] == 1)]
Mujair = fish2.loc[(fish2['Jenis'] == 0)]
WeightGurame = Gurame['Weight']
LengthGurame = Gurame['Length']
WeightMujair = Mujair['Weight']
LengthMujair = Mujair['Length']

plt.figure(figsize=(15,7))
plt.plot(WeightGurame, LengthGurame, "bs", linewidth=0, label="Ikan Gurame")
plt.plot(WeightMujair, LengthMujair, "go", linewidth=0, label="Ikan Mujair")
plt.plot(xd, yd, 'red', lw=1, ls='--')
plt.xlabel("Weight", fontsize=14)
plt.ylabel("Length", fontsize=14)
plt.legend()
plt.show()

"""**G. *Cross Validation* dengan 5-Fold**

Gunakan metode *cross validation* dengan 5-fold (`cv=5`), dan kemudian tentukan *cross validation score-nya*
"""

# kode poin G di sini
x,X_test,y,y_test=train_test_split(X_train,y_train,test_size=0.2)

score = log_reg.score(X_test, y_test)
print('Test Accuracy Score', score)

from sklearn.model_selection import cross_val_predict
y_train_pred = cross_val_predict(log_reg, X_train, y_train, cv=5)
score = log_reg.score(X_train, y_train_pred)
print('Test Accuracy Score', score)

"""Apa kesimpulan anda dengan hasil tersebut?

Kami mendapat akurasi sebesar 0.96/ 96% dari data csv

**H. Tentukan *Confusion Matrix*, *Precision* dan *Recall***
"""

# kode poin H di sini
from sklearn.metrics import confusion_matrix
confusion_matrix(y_train, y_train_pred)

import seaborn as sns
import matplotlib.pyplot as plt
f, ax = plt.subplots(figsize=(8,5))
sns.heatmap(confusion_matrix(y_train, y_train_pred), annot=True, fmt=".0f", ax=ax)
plt.xlabel("Sumbu y")
plt.ylabel("Sumbu x")
plt.show()

from sklearn.metrics import precision_score
precision_score(y_train, y_train_pred)

from sklearn.metrics import recall_score
recall_score(y_train, y_train_pred)

from sklearn.metrics import f1_score
f1_score(y_train, y_train_pred)

"""Apa kesimpulan anda dengan hasil tersebut?

Nilai presisi sebesar 91% dan recall sebesar 91%

#### **2.2. Berikut adalah langkah-langkah solusi *Stochastic Gradient Descent Classifier* yang anda gunakan untuk membantu Joko melakukan klasifikasi jenis ikan Gurame atau Ikan Mujair**

Catatan:
* Gunakan `SGDClassifier` dari model `linear` pada `Scikit-Learn`.
* Ikuti langkah langkah seperti pada soal 2.1 dari C s/d H, kecuali nomor F tidak perlu dikerjakan.
* Anda bisa menggunakan *scaling* jika dibutuhkan (lihat contoh pada **Chapter 3**, bagian **7. Multiclass Classifier**)

Setelah selesai, maka bandingkan hasil *confussion matrix*, *precission* dan *recall* dari metode regresi logistik dan SGD. **Berikan komentar anda**.
"""

#load data
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns


fish2 = pd.read_csv('IkanIndo01.csv')
print(fish2)

X = fish2.iloc[:, [0, 1]].values
y = fish2.iloc[:, 2].values
print(X,y)

#plot data
Gurame = fish2.loc[(fish2['Jenis'] == 1)]
Mujair = fish2.loc[(fish2['Jenis'] == 0)]
WeightGurame = Gurame['Weight']
LengthGurame = Gurame['Length']
WeightMujair = Mujair['Weight']
LengthMujair = Mujair['Length']
plt.figure(figsize=(15,7))
plt.plot(WeightGurame, LengthGurame, "bs", linewidth=0, label="Gurame")
plt.plot(WeightMujair, LengthMujair, "go", linewidth=0, label="Mujair")
plt.xlabel("Weight", fontsize=14)
plt.ylabel("Length", fontsize=14)
plt.legend()
plt.show()

#Model SGDclassifier
from sklearn.linear_model import SGDClassifier
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y.ravel(), test_size = 0.25, random_state = 0)

sgd_clf = SGDClassifier(max_iter=1000, tol=0.0001, random_state=42)
sgd_clf.fit(X_train,y_train)

y_prediksi = sgd_clf.predict(X_test)
from sklearn.metrics import accuracy_score
acc1 = accuracy_score(y_test,y_prediksi)
print("Accuracy : ", acc1)

#cross validation prediction dengan cv=5
from sklearn.model_selection import cross_val_predict
y_train_pred = cross_val_predict(sgd_clf, X_train, y_train, cv=5)

from sklearn.metrics import confusion_matrix
confusion_matrix(y_train, y_train_pred)

import seaborn as sns
import matplotlib.pyplot as plt
f, ax = plt.subplots(figsize=(8,5))
sns.heatmap(confusion_matrix(y_train, y_train_pred), annot=True, fmt=".0f", ax=ax)
plt.xlabel("Sumbu y")
plt.ylabel("Sumbu x")
plt.show()

from sklearn.metrics import precision_score
prec1 = precision_score(y_train, y_train_pred)
print("Presisi : ", prec1)

from sklearn.metrics import recall_score
recall1 = recall_score(y_train, y_train_pred)
print("Recall1 : ", recall1)

from sklearn.metrics import f1_score
f1 = f1_score(y_train, y_train_pred)
print("F1-Score : ", f1)

"""## 3. Klasifikasi dengan Decision Tree dan Ensamble Learning

Anda sebagai seorang pegawai baru di sebuah perusahaan yang bergerak di bidang *Data Mining* diberikan tugas untuk melakukan klasifikasi bahwa seseorang terkena Kanker (*cancer*) jinak (*benign*) atau ganas (*malignant*) berdasarkan data set di alamat berikut: [**Data Kanker**](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html). 

Berdasarkan dataset tersebut untuk mengklasifikasikan jenis kanker ganas atau jinak, didasarkan pada ukuran tumor, dengan *feature* sebanyak 30. Tetapi, anda hanya diberikan tugas untuk menggunakan 3 *feature* saja, dengan aturan sebagai berikut berdasarkan kelompok:

1. Kelompok 1 : gunakan feature 'mean radius', 'mean texture', 'mean perimeter'
2. Kelompok 2 : gunakan feature 'mean texture', 'mean perimeter', 'mean area',
3. Kelompok 3 : gunakan feature 'mean perimeter', 'mean area', 'mean smoothness'
4. Kelompok 4 : gunakan feature 'mean smoothness', 'mean compactness', 'mean concavity',
5. Kelompok 5 : gunakan feature 'mean area', 'mean smoothness', 'mean compactness'
6. Kelompok 6 : gunakan feature 'mean smoothness', 'mean compactness','mean concave points'
7. Kelompok 7 : gunakan feature 'mean compactness','mean concave points', 'mean symmetry'
8. Kelompok 8 : gunakan feature 'mean concave points', 'mean symmetry', 'mean fractal dimension'

indeks kolom dari setiap *feature* di atas bisa dilihat di link berikut: [nomor kolom](https://scikit-learn.org/stable/datasets/index.html#breast-cancer-dataset), yaitu sesuai urutan berikut: radius, texture, perimeter,..., dst.
Contoh: indeks kolom 0 untuk 'mean radius', 1 untuk 'mean texture',..., dst

*Class* atau target yang digunakan:
Target 
* WDBC-Malignant (ganas) sebanyak 212 data
* WDBC-Benign (jinak) sebanyak 357 data

Oleh atasan, anda diharuskan dapat menjawab pertanyaan-pertanyaan berikut dengan bukti program yang telah anda buat:

1. Dengan *class* `DecisionTreeClassifier` menggunakan *4-fold cross validation*, maka bandingakan *validation score* antara `DecisionTreeClassifier` memakai *gini impurity* dan *entropy impurity*!
2. Bandingkan *accuracy score* untuk `DecisionTreeClassifier` **tanpa dan dengan *pasting*** (estimator = 100, max_samples = 100)!
3. Perlihatkan *confusion matrix* dari hasil *ensemble learning classification* dari regresi logistik, svm dan *decision tree*, dan hitunglah nilai *precision* dan *recall* masing-masing!

Catatan: 
* Anda dapat mengikuti langkah-langkah seperti pada nomor 1 atau 2 sebelumnya untuk membuat program, atau anda bisa buat sekaligus dalam satu cell.
* Referensi yang digunakan adalah ***Chapter 4***.
"""

# Program untuk soal no.3 dimulai di sini
# Load Data
from sklearn.datasets import load_breast_cancer
import numpy as np
import pandas as pd

cancer = load_breast_cancer()

data = cancer.data[:]
target = cancer.target

table = []

for i in range (0, len(data)):
  t = {
      'Mean Radius' : data[i][0],
      'Mean Texture' : data[i][1],
      'Mean Perimeter' : data[i][2],
      'Mean Area' : data[i][3],
      'Mean Smoothness' : data[i][4],
      'Mean Compactness' : data[i][5],
      'Mean Concavity' : data[i][6],
      'Mean Concave Point' : data[i][7],
      'Mean Symmetry' : data[i][8],
      'Mean Fracral Dimension' : data[i][9],
      'Diagnosis' : target[i],
      }
  table.append(t)
df = pd.DataFrame(table)
df

#mencari mean smoothness, mean compactness, mean concavity
data = data[:,[4, 5, 6]] #ambil datanya
print(data)

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
x = data 
y = target

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 100)

clf = DecisionTreeClassifier(criterion = 'gini', max_depth=5)
clf = clf.fit(x_train, y_train)

y_pred = clf.predict(x_test)
print(y_pred)

from sklearn import metrics

metric = metrics.accuracy_score(y_test, y_pred)
print("Accuracy : ", metric)

#gini impurty
from sklearn.tree import export_graphviz
from sklearn.tree import export_graphviz
# from sklearn.externals.six import StringIO
from six import StringIO
from IPython.display import Image
import pydotplus

feature_cols = ['Smoothness', 'Compactness', 'Concavity',]

dot_data = StringIO()
export_graphviz(
    clf, out_file=dot_data,
    filled=True, rounded = True,
    special_characters = True,
    feature_names = feature_cols,
    class_names = ['0', '1']
    )

graph = pydotplus.graph_from_dot_data(dot_data.getvalue())
graph.write_png('Decision_tree_gini.png')
Image(graph.create_png())

# entropy
clf = DecisionTreeClassifier(criterion = 'entropy', max_depth=5) 
clf = clf.fit(x_train, y_train)

y_pred = clf.predict(x_test)
print(y_pred)

acc = metrics.accuracy_score(y_test, y_pred)
print("Accuracy : ", acc)

feature_cols = ['Smoothness', 'Compactness', 'Concavity',]

dot_data = StringIO()
export_graphviz(
    clf, out_file=dot_data,
    filled=True, rounded = True,
    special_characters = True,
    feature_names = feature_cols,
    class_names = ['0', '1']
    )

graph = pydotplus.graph_from_dot_data(dot_data.getvalue())
graph.write_png('Decision_tree_entropy.png')
Image(graph.create_png())

"""2. Bandingkan *accuracy score* untuk `DecisionTreeClassifier` **tanpa dan dengan *pasting*** (estimator = 100, max_samples = 100)!"""

from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier
bagging_clf = BaggingClassifier(
  DecisionTreeClassifier(random_state=42), n_estimators=100,
  max_samples=100, bootstrap=False, random_state=42)
bagging_clf.fit(x, y)
y_pred = bag_clf.predict(x)

# Akurasi dengan Pasting Classifier
from sklearn.metrics import accuracy_score
print(accuracy_score(y, y_pred))

# Akurasi Decision tree Classifier
tree_clf = DecisionTreeClassifier(random_state=42)
tree_clf.fit(x, y)
y_pred_clf_tree = tree_clf.predict(x)
print(accuracy_score(y, y_pred_clf_tree))

"""Dapat disimpulkan nilai akurasi decision tree lebih baik dibandingkan dengan nilai akurasi dari pasting classifier

3. Perlihatkan confusion matrix dari hasil ensemble learning classification dari regresi logistik, svm dan decision tree, dan hitunglah nilai precision dan recall masing-masing!
"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
log_reg_clf = LogisticRegression(solver="lbfgs", random_state=42) 
ranfor_clf = RandomForestClassifier(n_estimators=100, random_state=42)
svm_clf = SVC(gamma="scale", random_state=42)
voting_clf = VotingClassifier(estimators=[('lr', log_reg_clf), ('rf', ranfor_clf), ('svm', svm_clf)],voting='hard')

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=42)

voting_clf.fit(x_train, y_train)

from sklearn.metrics import confusion_matrix
for clf in (log_reg_clf, randfor_clf, svc_clf, voting_clf):
  clf.fit(x_train, y_train)
  y_pred = clf.predict(x_test)
  print('Matriks',clf.__class__.__name__,'= ', confusion_matrix(y_test, y_pred))

from sklearn.metrics import precision_score
for clf in (log_reg_clf, randfor_clf, svc_clf, voting_clf):
  clf.fit(x_train, y_train)
  y_pred = clf.predict(x_test)
  print('Presisi ',clf.__class__.__name__,'= ', precision_score(y_test, y_pred))

from sklearn.metrics import recall_score
for clf in (log_reg_clf, randfor_clf, svc_clf, voting_clf):
  clf.fit(x_train, y_train)
  y_pred = clf.predict(x_test)
  print('recall ',clf.__class__.__name__,'= ', recall_score(y_test, y_pred))

